<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Romain Ferrali" />

<meta name="date" content="2017-07-20" />

<title>Introduction to banditr</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Introduction to <code>banditr</code></h1>
<h4 class="author"><em>Romain Ferrali</em></h4>
<h4 class="date"><em>2017-07-20</em></h4>



<p>As Scott <span class="citation">(2010)</span> defines:</p>
<blockquote>
<p>A <em>multi-armed bandit</em> is a sequential experiment with the goal of achieving the largest possible reward from a payoff distribution with unknown parameters. At each stage, the experimenter must decide which arm of the experiment to observe next. The choice involves a fundamental trade-off between the utility gain from exploiting arms that appear to be doing well (based on limited sample information) vs exploring arms that might potentially be optimal, but which appear to be inferior because of sampling variability.</p>
</blockquote>
<p>The <code>banditr</code> package implements several popular algorithms that solve the multi-armed bandit problem. Currently, the package supports two algorithms:</p>
<ul>
<li>Thompson sampling <span class="citation">(Scott 2010)</span>, using the <a href="https://cran.r-project.org/web/packages/rstanarm/index.html"><code>rstanarm</code></a> package.</li>
<li>Linear Upper Confidence Bound <span class="citation">(LinUCB, Li et al. 2010)</span>, with optional dimensionality reduction (Egami &amp; Imai ???), using the <a href="https://cran.r-project.org/web/packages/glmnet/index.html"><code>glmnet</code></a> package.</li>
</ul>
<p>The <code>banditr</code> package provides a comprehensive solution that handles the entire experimental sequence. Because such sequential experiments may involve large amounts of data, the package allows storing its data locally, as a self-contained R object, but also remotely, using the host’s filesystem and a database management system (DBMS). Currently, the package supports one DBMS: Microsoft SQL Server, through the <a href="https://cran.r-project.org/web/packages/RODBC/index.html"><code>RODBC</code></a> package.</p>
<p>This vignette gives an overview of how <code>banditr</code> handles <code>bandit</code> objects, using a LinUCB bandit as an example. Another vignette details how to use <code>banditr</code> with a DBMS.</p>
<div id="bandit-algorithms" class="section level2">
<h2>Bandit algorithms</h2>
<p>In the multi-armed bandit problem, the experimenter starts with <span class="math inline">\(N_0\)</span> completed experiments for which she observes the vector of outcomes <span class="math inline">\(Y_0\)</span>, and the <span class="math inline">\(N_0 \times K\)</span> matrix <span class="math inline">\(X_0\)</span> of features. She has an <span class="math inline">\(R_0 \times K\)</span> matrix <span class="math inline">\(Z\)</span> of characteristics for treatment arms for which she does not observe the outcome. At each time period <span class="math inline">\(t\)</span>, she selects a treatment arm <span class="math inline">\(i\)</span> for which she observes the outcome <span class="math inline">\(y_i\)</span>. Her goal is to solve the following maximization problem: <span class="math display">\[
\max_{i \in \{1,...,R_t\}} y_i. 
\]</span></p>
<p>Bandit algorithms implement mechanisms to solve this maximization problem. Suppose the model <span class="math inline">\(Y = X \beta\)</span>. The LinUCB and Thompson sampling algorithms perform a similar task at each time period. They update the model using completed experiments, and provide a rule <span class="math inline">\(f(\beta_t, Z_t): (\mathcal{R}^{K}, \mathcal{R}^{(R_t \times K)}) \rightarrow \{1,...,R_t\}\)</span> to select the next next treatment arm:</p>
<ul>
<li>Observe the outcome <span class="math inline">\(y_i\)</span> of the treatment arm selected at <span class="math inline">\(t-1\)</span>.</li>
<li><span class="math inline">\(Y_t \leftarrow (Y_{t-1}, y_i), X_t \leftarrow (X_{t-1}, z_i^T)\)</span></li>
<li>Update the model parameters <span class="math inline">\(\hat{\beta}_t\)</span> by estimating the model <span class="math inline">\(Y_t = X_t \beta\)</span>.</li>
<li>Select the treatment arm <span class="math inline">\(i = f(\beta_t, Z_t)\)</span></li>
</ul>
<div id="specifics-of-linucb" class="section level3">
<h3>Specifics of LinUCB</h3>
<p>Let <span class="math inline">\(\hat{y}_{it}\)</span> be the predicted outcome for treatment arm <span class="math inline">\(i\)</span>. At each time period <span class="math inline">\(t\)</span>, the LinUCB algorithm selects the experimental arm <span class="math inline">\(i\)</span> that maximizes <span class="math inline">\(p(i,t) = \hat{y}_i^T \beta_t + \alpha U_t(i)\)</span>, where <span class="math inline">\(U_t(i) = \sqrt{z_i^T\left(X_t^T X_t + \lambda I_K \right)^{-1} z_i}\)</span>. The parameter <span class="math inline">\(\alpha \geq 0\)</span> is a tuning parameter that arbitrates between exploitation (selecting treatment arms with a high predicted reward <span class="math inline">\(\hat{y}_i\)</span>), and exploration (selecting treatment arms with high uncertainty <span class="math inline">\(U_t(i)\)</span>). The parameter <span class="math inline">\(\lambda &gt; 0\)</span> introduces ridge regularization.</p>
<p>For modelling, the package currently supports linear, and logistic regressions with ridge regularization, and allows for a first stage of variable selection using the LASSO, as well as the automatic selection of tuning parameters using <span class="math inline">\(K-fold\)</span> cross-validation. All these functionalities are implemented using the <code>glmnet</code> package, wrapped into the new <code>banditGlmnet</code> class, that supports the formula interface.</p>
</div>
<div id="specifics-of-thompson-sampling" class="section level3">
<h3>Specifics of Thompson sampling</h3>
<p>The Thomspon sampling algorithm operate in a Bayesian framework. At each time period, the algorithm selects the next experimental arm at random, with a weight that is a function of the posterior expected predicted probability of maximizing the reward. Let <span class="math inline">\(\hat{y}_{it}(\beta)\)</span> be the predicted outcome for treatment arm <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> for parameters <span class="math inline">\(\beta\)</span>, and define <span class="math inline">\(I_{it}(\beta) = 1\)</span> if treatment arm <span class="math inline">\(i\)</span> solves <span class="math inline">\(\max_{i \in (1, ..., Z_t)} \hat{y}_{it}(\beta)\)</span>, and <span class="math inline">\(I_{it}(\beta) = 0\)</span> otherwise. Then the Thompson sampling weights for arm <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> can be estimated with the following: <span class="math display">\[
w_{it} = \frac{1}{M} \sum_{m=1}^M I_{it}(\beta^{(m)}), 
\]</span> where <span class="math inline">\(\beta^{(m)}\)</span> is the <span class="math inline">\(m\)</span>-th draw from the posterior distribution at time <span class="math inline">\(t\)</span>. The equation basically defines weights as the proportion of posterior draws for which <span class="math inline">\(i\)</span> is maximal. One can set the amount of exploration by sampling according to some weight <span class="math inline">\(w_{it}^\gamma\)</span>, where the algorithm will tend to explore more for <span class="math inline">\(\gamma &lt; 1\)</span>, and exploit more for <span class="math inline">\(\gamma &gt; 1\)</span>.</p>
<p>For modelling, the package currently supports linear, and logistic regressions, as well as random effect models. Estimation is conducted using the <code>rstanarm</code> package.</p>
</div>
</div>
<div id="creating-a-bandit-object" class="section level2">
<h2>Creating a bandit object</h2>
<p>First, let’s simulate data according to the following payoff distribution: <span class="math display">\[
\Pr(y_i = 1 | x_i) = \text{logit}\left(\sum_{j=-4}^{5} \beta_j x_{ij}  \right), 
\]</span> where <span class="math inline">\(\text{logit}\)</span> is the logistic function <span class="math inline">\(\text{logit}(x) = \frac{1}{1+\exp(-x)}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">999</span>)
x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="fl">10e3</span>), <span class="fl">1e3</span>, <span class="dv">10</span>)
beta &lt;-<span class="st"> </span>-<span class="dv">4</span>:<span class="dv">5</span>
y &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">plogis</span>(x %*%<span class="st"> </span>beta))
y &lt;-<span class="st"> </span><span class="kw">sapply</span>(y, rbinom, <span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span>)
<span class="kw">colnames</span>(x) &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;v&quot;</span>, <span class="dv">1</span>:<span class="dv">10</span>)

df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(x)
df &lt;-<span class="st"> </span><span class="kw">cbind</span>(y, df)</code></pre></div>
<p>The package uses Reference Classes (RC) to store bandit objects. To handle future samples in the experimental sequence, the data needs to contain an <code>id</code> column, that serves as a primary key, and a column named <code>y</code> that contains the ouctome.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">id =</span> <span class="dv">1</span>:<span class="dv">1000</span>, df) <span class="co"># add a primary key to the data</span></code></pre></div>
<p>In this vignette, we create a LinUCB bandit that uses a binomial logistic regression. By default, the package uses a value of <span class="math inline">\(\alpha = 1\)</span> as a tuning parameter. Let’s create a LinUCB bandit and inspect it.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(banditr) <span class="co"># initialize the bandit using the first 100 samples</span>
start &lt;-<span class="st"> </span>df[<span class="dv">1</span>:<span class="dv">100</span>,]
bdt_ucb &lt;-<span class="st"> </span><span class="kw">bandit_ucb</span>(<span class="dt">formula =</span> y ~<span class="st"> </span>-<span class="dv">1</span> +<span class="st"> </span>v1 +<span class="st"> </span>v2 +<span class="st"> </span>v3 +<span class="st"> </span>v4 +<span class="st"> </span>v5 +<span class="st"> </span>v6 +<span class="st"> </span>v7 +<span class="st"> </span>v8 +<span class="st"> </span>v9 +<span class="st"> </span>v10, 
                  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, 
                  <span class="dt">data =</span> start)
<span class="kw">summary</span>(bdt_ucb)</code></pre></div>
<pre><code>## Bandit started 2017-07-20 17:36:17
## Formula: y ~ -1 + v1 + v2 + v3 + v4 + v5 + v6 + v7 + v8 + v9 + v10
## 
## Family: 
## binomial
## 
## Coefficients: 
## No training job found. 
## 
## Size of training set: 100 samples
## Number of training jobs: 0
## Number of tuning jobs: 0
## Reward: 0/0
## 
## Last jobs:
##  job                date       type param value
##    1 2017-07-20 17:36:17 initialize    NA    NA</code></pre>
<p>Thomspon sampling bandits are created in a similar way, and use a default value <span class="math inline">\(\gamma = 1\)</span> for the tuning parameter:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bdt_thom &lt;-<span class="st"> </span><span class="kw">bandit_stan_glm</span>(<span class="dt">formula =</span> y ~<span class="st"> </span>-<span class="dv">1</span> +<span class="st"> </span>v1 +<span class="st"> </span>v2 +<span class="st"> </span>v3 +<span class="st"> </span>v4 +<span class="st"> </span>v5 +<span class="st"> </span>v6 +<span class="st"> </span>v7 +<span class="st"> </span>v8 +<span class="st"> </span>v9 +<span class="st"> </span>v10, 
                  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, 
                  <span class="dt">data =</span> start)</code></pre></div>
</div>
<div id="managing-the-experiment" class="section level2">
<h2>Managing the experiment</h2>
<p>The user manages the experiment by performing jobs on the bandit. First, let’s update the model using our current training set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bdt_ucb$<span class="kw">train</span>()
bdt_thom$<span class="kw">train</span>(<span class="dt">chains =</span> <span class="dv">1</span>) <span class="co"># use only one Markov chain for demonstration purposes</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).
## 
## Gradient evaluation took 0 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 0.736 seconds (Warm-up)
##                0.763 seconds (Sampling)
##                1.499 seconds (Total)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(bdt_ucb)</code></pre></div>
<pre><code>## Bandit started 2017-07-20 17:36:17
## Formula: y ~ -1 + v1 + v2 + v3 + v4 + v5 + v6 + v7 + v8 + v9 + v10
## 
## Family: 
## binomial
## 
## Coefficients: 
## (Intercept)          v1          v2          v3          v4          v5 
##      0.0000     -6.1726     -2.9095     -2.2445     -1.0964      1.4699 
##          v6          v7          v8          v9         v10 
##      1.8523      3.7527      4.3398      5.4517      6.5306 
## 
## Size of training set: 100 samples
## Number of training jobs: 1
## Number of tuning jobs: 0
## Reward: 0/0
## 
## Last jobs:
##  job                date       type param value
##    1 2017-07-20 17:36:17 initialize    NA    NA
##    2 2017-07-20 17:36:17      train    NA    NA</code></pre>
<p>We then add experimental arms to the bandit, and obtain their score (for the LinUCB algorithm), and their sampling weight (for the Thomspon sampling algorithm):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">add &lt;-<span class="st"> </span>df[<span class="dv">101</span>:<span class="dv">1000</span>,]
add$y &lt;-<span class="st"> </span><span class="ot">NA</span> <span class="co"># let's pretend we haven't observed the reward yet. </span>
bdt_ucb$<span class="kw">addSamples</span>(add)
bdt_thom$<span class="kw">addSamples</span>(add)

pr_ucb &lt;-<span class="st"> </span><span class="kw">predict</span>(bdt_ucb)
pr_thom &lt;-<span class="st"> </span><span class="kw">predict</span>(bdt_thom)</code></pre></div>
<pre><code>## Called from: .local(object, ...)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#150: response &lt;- rstanarm::posterior_linpred(data$model, transform = TRUE, 
##     newdata = data$samples, re.form = re.form)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#154: if (&quot;response&quot; %in% type) {
##     out$response &lt;- colMeans(response)
## }
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#155: out$response &lt;- colMeans(response)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#157: if (&quot;weight&quot; %in% type) {
##     w &lt;- apply(response, 1, which.max)
##     w &lt;- table(w)
##     w &lt;- w[match(1:ncol(response), names(w))]
##     w[is.na(w)] &lt;- 0
##     w &lt;- w/sum(w)
##     w &lt;- as.numeric(w)
##     out$weight &lt;- w
## }
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#158: w &lt;- apply(response, 1, which.max)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#159: w &lt;- table(w)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#160: w &lt;- w[match(1:ncol(response), names(w))]
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#161: w[is.na(w)] &lt;- 0
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#162: w &lt;- w/sum(w)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#163: w &lt;- as.numeric(w)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#164: out$weight &lt;- w
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#167: makePredict(out, names = id)</code></pre>
<p>For LinUCB bandits, the <code>predict</code> method returns a <code>data.frame</code> with the predicted response of all experimental arms whose outcome is missing, and their score. The LinUCB algorithm requires observing the outcome of the experimental arm with the highest score.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(pr_ucb)</code></pre></div>
<pre><code>##         response uncertainty     score
## 101 7.231030e-12   0.4228400 0.4228400
## 102 9.393602e-01   0.3499187 1.2892789
## 103 9.061797e-01   0.3338683 1.2400480
## 104 3.404016e-02   0.2212835 0.2553237
## 105 6.698767e-01   0.3353260 1.0052026
## 106 9.994085e-01   0.4381338 1.4375423</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">id_ucb &lt;-<span class="st"> </span><span class="kw">rownames</span>(pr_ucb)[<span class="kw">which.max</span>(pr_ucb$score)]
y_ucb &lt;-<span class="st"> </span>df$y[df$id ==<span class="st"> </span>id_ucb]
y_ucb</code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>The Thompson sampling algorithm requires sampling the next observation using the Thompson weights.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(pr_thom)</code></pre></div>
<pre><code>##         response weight
## 101 6.133249e-06      0
## 102 7.780171e-01      0
## 103 6.658570e-01      0
## 104 2.291221e-01      0
## 105 6.888573e-01      0
## 106 9.499972e-01      0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">id_thom &lt;-<span class="st"> </span><span class="kw">rownames</span>(pr_thom)[<span class="kw">sample.int</span>(<span class="kw">nrow</span>(pr_thom), <span class="dv">1</span>, <span class="dt">prob =</span> pr_thom$weight)]
y_thom &lt;-<span class="st"> </span>df$y[df$id ==<span class="st"> </span>id_thom]
y_thom</code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Let’s add this newly observed outcome to the bandit, and update the model with this new information. Outcomes must be added as a named vector, with names pointing to the ids of the corresponding arms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(y_ucb) &lt;-<span class="st"> </span>id_ucb
bdt_ucb$<span class="kw">addOutcomes</span>(y_ucb) <span class="co"># add the new outcome to the bandit</span>
bdt_ucb$<span class="kw">train</span>() <span class="co"># update it</span>

<span class="kw">names</span>(y_thom) &lt;-<span class="st"> </span>id_thom <span class="co"># likewise, for the Thompson bandit</span>
bdt_thom$<span class="kw">addOutcomes</span>(y_thom)</code></pre></div>
<pre><code>## Called from: .local(object, ...)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#150: response &lt;- rstanarm::posterior_linpred(data$model, transform = TRUE, 
##     newdata = data$samples, re.form = re.form)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#154: if (&quot;response&quot; %in% type) {
##     out$response &lt;- colMeans(response)
## }
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#155: out$response &lt;- colMeans(response)
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#157: if (&quot;weight&quot; %in% type) {
##     w &lt;- apply(response, 1, which.max)
##     w &lt;- table(w)
##     w &lt;- w[match(1:ncol(response), names(w))]
##     w[is.na(w)] &lt;- 0
##     w &lt;- w/sum(w)
##     w &lt;- as.numeric(w)
##     out$weight &lt;- w
## }
## debug at C:\Users\Romain\Dropbox\projects\banditr/R/predict.R#167: makePredict(out, names = id)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bdt_thom$<span class="kw">train</span>(<span class="dt">chains =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).
## 
## Gradient evaluation took 0 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 0.728 seconds (Warm-up)
##                0.924 seconds (Sampling)
##                1.652 seconds (Total)</code></pre>
<p>Note that the LinUCB bandit supports ridge regularization and variable selection with the LASSO. By default, the model uses neither. Both tuning parameters can be set manually, or using K-fold validation (with <code>cv.glmnet</code>). Let’s introduce some ridge regularization, and a stage of variable selection.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set the tuning parameter for ridge regularization to 1</span>
bdt_ucb$<span class="kw">tune</span>(<span class="dt">param =</span> <span class="st">'lambdaRidge'</span>, <span class="dt">value =</span> <span class="dv">1</span>) 
<span class="co"># select the tuning parameter for the LASSO using 10-fold cross validation </span>
bdt_ucb$<span class="kw">tune</span>(<span class="dt">param =</span> <span class="st">'lambdaLasso'</span>, <span class="dt">value =</span> <span class="st">'auto'</span>, <span class="dt">lambdaAuto =</span> <span class="st">'lambda.1se'</span>)</code></pre></div>
</div>
<div id="diagnostics" class="section level2">
<h2>Diagnostics</h2>
<p>The <code>banditr</code> package provides a few built-in diagnostic plots, and allows for convenient extraction of relevant objects for further exploration. First, let’s extend the experiment for a few more iterations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">for (i in <span class="dv">1</span>:<span class="dv">20</span>) {
  pr_ucb &lt;-<span class="st"> </span><span class="kw">predict</span>(bdt_ucb)
  id &lt;-<span class="st"> </span><span class="kw">rownames</span>(pr_ucb)[<span class="kw">which.max</span>(pr_ucb$score)]
  y &lt;-<span class="st"> </span>df$y[df$id ==<span class="st"> </span>id]
  <span class="kw">names</span>(y) &lt;-<span class="st"> </span>id
  bdt_ucb$<span class="kw">addOutcomes</span>(y)
  bdt_ucb$<span class="kw">train</span>()
}</code></pre></div>
<p>The package provides two diagnostics plots:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(bdt_ucb) <span class="co"># the default diagnostic: cumulative reward over time</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(bdt_ucb, <span class="dt">what =</span> <span class="st">&quot;coef&quot;</span>) <span class="co"># parameter values over time</span>
<span class="co"># plot(bdt, what = &quot;MSE&quot;)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>Besides the standard <code>coef</code> method to extract current model coefficients, other extraction methods are prefixed with <code>get</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(bdt_ucb)</code></pre></div>
<pre><code>## (Intercept)          v1          v2          v3          v4          v5 
##  0.00000000 -0.12063409 -0.04227612 -0.04343376  0.00000000  0.04148307 
##          v6          v7          v8          v9         v10 
##  0.03125325  0.10047335  0.12924281  0.12844259  0.15232601</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod &lt;-<span class="st"> </span><span class="kw">getModel</span>(bdt_ucb) <span class="co"># extract the last model</span>
mf &lt;-<span class="st"> </span><span class="kw">getSamples</span>(bdt_ucb) <span class="co"># extract complete samples</span>
jobs &lt;-<span class="st"> </span><span class="kw">getJobs</span>(bdt_ucb) <span class="co"># extract a summary of all jobs</span></code></pre></div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-Li2010a">
<p>Li, Lihong, Wei Chu, John Langford, and Robert E. Schapire. 2010. “A Contextual-Bandit Approach to Personalized News Article Recommendation.” In <em>WWW ’10 Proceedings of the 19th International Conference on World Wide Web</em>, 661–70. Railegh, NC: ACM. doi:<a href="https://doi.org/10.1145/1772690.1772758">10.1145/1772690.1772758</a>.</p>
</div>
<div id="ref-Scott2010">
<p>Scott, Steven L. 2010. “A modern Bayesian look at the multi-armed bandit.” <em>Applied Stochastic Models in Business and Industry</em> 26: 639–58. doi:<a href="https://doi.org/10.1002/asmb">10.1002/asmb</a>.</p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
